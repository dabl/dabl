# -*- coding: utf-8 -*-
"""demo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Noousz85g25d0DYi2oxNvXnOJOtYsiIR

# A quick demo of dabl on some toy datasets and slightly more interesting datasets

# Scikit-learn build-in datasets:

## Wine classification
"""

# !pip install dabl

# from google.colab import drive
# drive.mount('/content/drive')

# !git clone https://github.com/nrohan09-cloud/dabl.git

# %cd dabl

import dabl
from sklearn.datasets import load_wine
wine_df = dabl.utils.data_df_from_bunch(load_wine())
wine_df.head()

dabl.plot(wine_df, 'target')

# obviously LDA solved the problem as we can see in the last plot. I might just want to use LDA or another linear model.
# Or we see what the SimpleClassifier does:
sc = dabl.SimpleClassifier()
sc.fit(wine_df, target_col='target')

# logistic regression has slightly higher accuracy and macro-average recall (which is the main metric we use)
# than linear discriminant analysis. Not really a shocker.
dabl.explain(sc)

"""Interestingly the large coefficients don't really correspond to what's shown in the univariate or pairplots. Possibly because the data is very correlated? Who knows!
I assume we could create a simpler model with less features from the plots above. Maybe lasso next time?

## Ames housing dataset
"""

ames_df = dabl.datasets.load_ames()
ames_df.head()

dabl.plot(ames_df, 'SalePrice')

"""You can see that high-ordinality categorical variables were summarized with rare categories binned into "dabl_other".
Also, ``GarageCars`` should maybe be plotted as a categorical variable - and there's a garage that will be build in 2200 (it's the outlier that's dropped). Huh.
We were pretty aggressive with dropping "near-constant" features. Maybe being less agressive might be good in some situations?
``Overall Qual`` might also arguably be better shown as a categorical feature, though it's a bit unclear.
"""

dabl.plot(ames_df, 'SalePrice', type_hints={'Garage Cars': 'categorical'})

sr = dabl.SimpleRegressor()
sr.fit(ames_df, target_col='SalePrice')

dabl.explain(sr)

# The neighborhood seems to dominate, no continuous variable is in the top 10 highest coefficients.

